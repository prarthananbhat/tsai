{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S4 Assignement .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prarthananbhat/tsai/blob/master/S4_Assignement_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT",
        "colab_type": "code",
        "outputId": "c058faa6-363c-40c2-a828-a903fdcc63fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install torchsummary\n",
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-pmj6y5xUGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_example = enumerate(train_loader)\n",
        "test_example = enumerate(train_loader)\n",
        "train_batch_id,(train_example_data,train_example_target) = next(train_example)\n",
        "test_batch_id,(test_example_data,test_example_target) = next(test_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_zv15RvxpOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "2f692adf-afb2-4a24-bf09-58e7ffcecf3e"
      },
      "source": [
        "print(\"Images from Train set\")\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(train_example_data[i][0],cmap='gray')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()\n",
        "print(\"Images from Test set\")\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(test_example_data[i][0],cmap='gray')\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Images from Train set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEFCAYAAACl5zMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Images from Test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEFCAYAAACl5zMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFW9db6p8aB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        # nn.Conv2d(1, 8, 3, padding=1),\n",
        "        # nn.ReLU(),\n",
        "        # nn.BatchNorm2d(8),\n",
        "        nn.Conv2d(1, 16, 3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(32, 16, 1),\n",
        "        nn.Dropout(0.10)\n",
        "        )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        #nn.Conv2d(8, 16, 3, padding=1),\n",
        "        #nn.ReLU(),\n",
        "        #nn.BatchNorm2d(16),\n",
        "        nn.Conv2d(16, 32, 3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Conv2d(32, 16, 3),\n",
        "        nn.Dropout(0.10)\n",
        "        )\n",
        "    self.conv3 = nn.Sequential(\n",
        "        nn.Conv2d(16, 32, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.Conv2d(32, 10, 1),\n",
        "        nn.Dropout(0.15),\n",
        "        nn.AvgPool2d(3)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUGDtFx_b8JM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "4a0c6b76-2919-49e9-d5ec-3cf7cb94925f"
      },
      "source": [
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 28, 28]             160\n",
            "              ReLU-2           [-1, 16, 28, 28]               0\n",
            "       BatchNorm2d-3           [-1, 16, 28, 28]              32\n",
            "            Conv2d-4           [-1, 32, 28, 28]           4,640\n",
            "              ReLU-5           [-1, 32, 28, 28]               0\n",
            "       BatchNorm2d-6           [-1, 32, 28, 28]              64\n",
            "         MaxPool2d-7           [-1, 32, 14, 14]               0\n",
            "            Conv2d-8           [-1, 16, 14, 14]             528\n",
            "           Dropout-9           [-1, 16, 14, 14]               0\n",
            "           Conv2d-10           [-1, 32, 14, 14]           4,640\n",
            "             ReLU-11           [-1, 32, 14, 14]               0\n",
            "      BatchNorm2d-12           [-1, 32, 14, 14]              64\n",
            "        MaxPool2d-13             [-1, 32, 7, 7]               0\n",
            "           Conv2d-14             [-1, 16, 5, 5]           4,624\n",
            "          Dropout-15             [-1, 16, 5, 5]               0\n",
            "           Conv2d-16             [-1, 32, 3, 3]           4,640\n",
            "             ReLU-17             [-1, 32, 3, 3]               0\n",
            "      BatchNorm2d-18             [-1, 32, 3, 3]              64\n",
            "           Conv2d-19             [-1, 10, 3, 3]             330\n",
            "          Dropout-20             [-1, 10, 3, 3]               0\n",
            "        AvgPool2d-21             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 19,786\n",
            "Trainable params: 19,786\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 1.13\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 1.21\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a04c46fb-326f-4ba2-b836-129e56e76f1a"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "for epoch in range(1, 20):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.1328684538602829 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 36.95it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0632, Accuracy: 9839/10000 (98.39%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.044681306928396225 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 37.85it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0359, Accuracy: 9890/10000 (98.90%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.09411058574914932 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 37.67it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0336, Accuracy: 9901/10000 (99.01%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.03303017467260361 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.57it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0278, Accuracy: 9916/10000 (99.16%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.07121917605400085 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 40.22it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0251, Accuracy: 9924/10000 (99.24%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.026077650487422943 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.99it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0228, Accuracy: 9940/10000 (99.40%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.04380640387535095 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 37.25it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0289, Accuracy: 9905/10000 (99.05%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.12494625896215439 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.32it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 9942/10000 (99.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.022412626072764397 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.47it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0219, Accuracy: 9934/10000 (99.34%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.013483807444572449 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.93it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0208, Accuracy: 9937/10000 (99.37%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.011808718554675579 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.11it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0209, Accuracy: 9935/10000 (99.35%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.007228145841509104 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.66it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0253, Accuracy: 9924/10000 (99.24%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.03822583332657814 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.08it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0207, Accuracy: 9934/10000 (99.34%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.007581283804029226 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 40.58it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0238, Accuracy: 9929/10000 (99.29%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.01330836582928896 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.43it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0216, Accuracy: 9931/10000 (99.31%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.02561272121965885 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.53it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0204, Accuracy: 9932/10000 (99.32%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.007906273007392883 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.56it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0179, Accuracy: 9942/10000 (99.42%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.010380302555859089 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.50it/s]\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0222, Accuracy: 9927/10000 (99.27%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "loss=0.010745614767074585 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.85it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 0.0178, Accuracy: 9945/10000 (99.45%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mw74cqCDkHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}